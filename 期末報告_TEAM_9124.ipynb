{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjRG99FhVOMN03xKTk9e67",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CP200435/-_TEAM_9124/blob/main/%E6%9C%9F%E6%9C%AB%E5%A0%B1%E5%91%8A_TEAM_9124.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qle0_aEbSGs6"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJdTSv9ZSkc8",
        "outputId": "d9ea985f-4b76-4ff9-8146-752ef19f18f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.241 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 38.5/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "aGx9R24kSUVU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ä¸‹è¼‰è³‡æ–™é›†\n",
        "import gdown\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "#ä¸‹è¼‰training_image.zip\n",
        "# gdown.download(\"https://drive.google.com/uc?export=download&id=1FfrsOgeJKSHtRM3Q649HJvSF1l4blxpl\",\"/content/training_image.zip\")\n",
        "gdown.download(\"https://drive.google.com/uc?export=download&id=15jWkS3l4PFqvKAL9DW9DNzl94p4s3P_6\",\"/content/training_image.zip\")\n",
        "\n",
        "#ä¸‹è¼‰training_label.zip\n",
        "# gdown.download(\"https://drive.google.com/uc?export=download&id=1KmYS2JhAexpWWlzlo_qwoX1TifA1COWW\",\"/content/training_label.zip\")\n",
        "gdown.download(\"https://drive.google.com/uc?export=download&id=1K4n7G8zVK0_PtgkkAQFBEXJs-zJpElKG\",\"/content/training_label.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "i__5UouISqhW",
        "outputId": "435df186-bd94-4790-9dee-6a5852b9df2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?export=download&id=15jWkS3l4PFqvKAL9DW9DNzl94p4s3P_6\n",
            "From (redirected): https://drive.google.com/uc?export=download&id=15jWkS3l4PFqvKAL9DW9DNzl94p4s3P_6&confirm=t&uuid=f4f03d4d-1b77-40e8-9051-b896362773ba\n",
            "To: /content/training_image.zip\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.83G/1.83G [00:21<00:00, 83.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1K4n7G8zVK0_PtgkkAQFBEXJs-zJpElKG\n",
            "To: /content/training_label.zip\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 669k/669k [00:00<00:00, 77.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_label.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textwrap import dedent\n",
        "from pathlib import Path\n",
        "\n",
        "data_yaml = dedent(\n",
        "    \"\"\"\n",
        "train: \"./datasets/train/images\"\n",
        "val: \"./datasets/val/images\"\n",
        "test: \"./datasets/test/images\"\n",
        "\n",
        "names:\n",
        "  0: aortic_valve\n",
        "\"\"\"\n",
        ").strip()\n",
        "\n",
        "config_path = Path(\"aortic_valve_colab.yaml\")\n",
        "config_path.write_text(data_yaml + \"\\n\", encoding=\"utf-8\")\n",
        "\n",
        "print(f\"YAML saved to: {config_path.resolve()}\")\n",
        "print(data_yaml)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2y094KIe0BC",
        "outputId": "e48bc7cd-89d3-49df-965b-2c06b2ef7dfe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML saved to: /content/aortic_valve_colab.yaml\n",
            "train: \"./datasets/train/images\"\n",
            "val: \"./datasets/val/images\"\n",
            "test: \"./datasets/test/images\"\n",
            "\n",
            "names:\n",
            "  0: aortic_valve\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ä¸‹è¼‰è³‡æ–™é›†\n",
        "import gdown\n",
        "import os\n",
        "!mkdir ./datasets\n",
        "!mkdir ./datasets/test\n",
        "gdown.download(\"https://drive.google.com/uc?export=download&id=13y81TV-z4_fbm7fCmjb0w_FvnPEZIHHa\",\"/content/datasets/testing.zip\")\n",
        "!unzip '/content/datasets/testing' -d '/content/datasets/test/tmp'"
      ],
      "metadata": {
        "id": "MYA9enLRTC4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, shutil  #week10hw\n",
        "\n",
        "def unzip_if_needed(zip_path, dest_dir):\n",
        "    if os.path.isdir(dest_dir):\n",
        "        return\n",
        "\n",
        "    if os.path.exists(zip_path):\n",
        "        os.makedirs(dest_dir, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "            zf.extractall(dest_dir)\n",
        "\n",
        "def find_patient_root(root):\n",
        "    for dirpath, dirnames, _ in os.walk(root):\n",
        "        if any(d.startswith(\"patient\") for d in dirnames):\n",
        "            return dirpath\n",
        "    return root\n",
        "\n",
        "# * è§£å£“ç¸® (ä¸ä½¿ç”¨å¤–éƒ¨ unzip æŒ‡ä»¤)\n",
        "unzip_if_needed(\"training_image.zip\", \"../training_image\")\n",
        "unzip_if_needed(\"training_label.zip\", \"../training_label\")\n",
        "\n",
        "IMG_ROOT = find_patient_root(\"../training_image\")\n",
        "LBL_ROOT = find_patient_root(\"../training_label\")\n",
        "\n",
        "# * å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾\n",
        "for p in [\"./datasets/train/images\", \"./datasets/train/labels\",\n",
        "          \"./datasets/val/images\", \"./datasets/val/labels\",\n",
        "          \"./datasets/test/images\", \"./datasets/test/labels\"]:\n",
        "    os.makedirs(p, exist_ok=True)"
      ],
      "metadata": {
        "id": "4BoTgNW3TZwp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week10\n",
        "def move_patients(start, end, split):\n",
        "    # train/val è®€å‰å¹¾ç­†ç—…æ‚£ï¼Œå¾Œé¢ç•¶ä½œ test ä¿ç•™å®Œæ•´å½±åƒ\n",
        "    moved = 0\n",
        "\n",
        "    for i in range(start, end + 1):\n",
        "        patient = f\"patient{i:04d}\"\n",
        "        img_dir = os.path.join(IMG_ROOT, patient)\n",
        "        lbl_dir = os.path.join(LBL_ROOT, patient)\n",
        "        if not os.path.isdir(img_dir):\n",
        "            continue\n",
        "\n",
        "        if split == \"test\":\n",
        "            label_lookup = {}\n",
        "            if os.path.isdir(lbl_dir):\n",
        "                for frame in os.listdir(lbl_dir):\n",
        "                    if frame.endswith(\".txt\"):\n",
        "                        label_lookup[os.path.splitext(frame)[0]] = os.path.join(lbl_dir, frame)\n",
        "\n",
        "            for frame in os.listdir(img_dir):\n",
        "                if not frame.lower().endswith(\".png\"):\n",
        "                    continue\n",
        "\n",
        "                base = os.path.splitext(frame)[0]\n",
        "                img_path = os.path.join(img_dir, frame)\n",
        "                dst_img = f\"./datasets/{split}/images/{base}.png\"\n",
        "\n",
        "                if os.path.exists(dst_img):\n",
        "                    os.remove(dst_img)\n",
        "                shutil.move(img_path, dst_img)\n",
        "\n",
        "                lbl_path = label_lookup.get(base)\n",
        "                if lbl_path and os.path.exists(lbl_path):\n",
        "                    dst_lbl = f\"./datasets/{split}/labels/{base}.txt\"\n",
        "                    if os.path.exists(dst_lbl):\n",
        "                        os.remove(dst_lbl)\n",
        "                    shutil.move(lbl_path, dst_lbl)\n",
        "\n",
        "                moved += 1\n",
        "\n",
        "        else:\n",
        "            if not os.path.isdir(lbl_dir):\n",
        "                continue\n",
        "\n",
        "            for lbl_name in os.listdir(lbl_dir):\n",
        "                if not lbl_name.endswith(\".txt\"):\n",
        "                    continue\n",
        "\n",
        "                base = os.path.splitext(lbl_name)[0]\n",
        "                img_path = os.path.join(img_dir, base + \".png\")\n",
        "                lbl_path = os.path.join(lbl_dir, lbl_name)\n",
        "                if not os.path.exists(img_path):\n",
        "                    continue\n",
        "\n",
        "                dst_img = f\"./datasets/{split}/images/{base}.png\"\n",
        "                dst_lbl = f\"./datasets/{split}/labels/{base}.txt\"\n",
        "\n",
        "                if os.path.exists(dst_img):\n",
        "                    os.remove(dst_img)\n",
        "                shutil.move(img_path, dst_img)\n",
        "\n",
        "                if os.path.exists(dst_lbl):\n",
        "                    os.remove(dst_lbl)\n",
        "                shutil.move(lbl_path, dst_lbl)\n",
        "\n",
        "                moved += 1\n",
        "\n",
        "    return moved\n"
      ],
      "metadata": {
        "id": "zglJ4hIVTdCd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#week10\n",
        "n_train = move_patients(1, 40, \"train\")\n",
        "n_val = move_patients(41, 45, \"val\")\n",
        "n_test = move_patients(46, 50, \"test\")\n",
        "\n",
        "print(\"å®Œæˆç§»å‹•: train {} | val {} | test {}\".format(n_train, n_val, n_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAzEfX6gTo5G",
        "outputId": "ed4654e8-ee30-47fd-aaa3-1f86d58f753d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å®Œæˆç§»å‹•: train 2168 | val 292 | test 1817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('è¨“ç·´é›†åœ–ç‰‡æ•¸é‡ : ',len(os.listdir(\"./datasets/train/images\")))\n",
        "print('è¨“ç·´é›†æ¨™è¨˜æ•¸é‡ : ',len(os.listdir(\"./datasets/train/labels\")))\n",
        "print('é©—è­‰é›†åœ–ç‰‡æ•¸é‡ : ',len(os.listdir(\"./datasets/val/images\")))\n",
        "print('é©—è­‰é›†æ¨™è¨˜æ•¸é‡ : ',len(os.listdir(\"./datasets/val/labels\")))\n",
        "print('æ¸¬è©¦é›†åœ–ç‰‡æ•¸é‡ : ',len(os.listdir(\"./datasets/test/images\")))\n",
        "print('æ¸¬è©¦é›†æ¨™è¨˜æ•¸é‡ : ',len(os.listdir(\"./datasets/test/labels\")))\n",
        "print('ç¸½åœ–ç‰‡æ•¸é‡: ',len(os.listdir(\"./datasets/train/images\")) + len(os.listdir(\"./datasets/val/images\")) + len(os.listdir(\"./datasets/test/images\")))\n",
        "print('ç¸½æ¨™è¨˜æ•¸é‡: ',len(os.listdir(\"./datasets/train/labels\")) + len(os.listdir(\"./datasets/val/labels\")) + len(os.listdir(\"./datasets/test/labels\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tAsNybhUD01",
        "outputId": "2c799345-4523-4512-93df-7425c50e6038"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è¨“ç·´é›†åœ–ç‰‡æ•¸é‡ :  2168\n",
            "è¨“ç·´é›†æ¨™è¨˜æ•¸é‡ :  2168\n",
            "é©—è­‰é›†åœ–ç‰‡æ•¸é‡ :  292\n",
            "é©—è­‰é›†æ¨™è¨˜æ•¸é‡ :  292\n",
            "æ¸¬è©¦é›†åœ–ç‰‡æ•¸é‡ :  1817\n",
            "æ¸¬è©¦é›†æ¨™è¨˜æ•¸é‡ :  327\n",
            "ç¸½åœ–ç‰‡æ•¸é‡:  4277\n",
            "ç¸½æ¨™è¨˜æ•¸é‡:  2787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n.pt') #åˆæ¬¡è¨“ç·´ä½¿ç”¨YOLOå®˜æ–¹çš„é è¨“ç·´æ¨¡å‹ï¼Œå¦‚è¦ä½¿ç”¨è‡ªå·±çš„æ¨¡å‹è¨“ç·´å¯ä»¥å°‡'yolo12n.pt'æ›¿æ›æ‰\n",
        "results = model.train(data=\"./aortic_valve_colab.yaml\",\n",
        "            epochs=20, #è·‘å¹¾å€‹epoch\n",
        "            batch=16, #batch_size\n",
        "            imgsz=640, #åœ–ç‰‡å¤§å°640*640\n",
        "            device=0 #ä½¿ç”¨GPUé€²è¡Œè¨“ç·´\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8M6ZBhsUFcZ",
        "outputId": "a19bf645-555f-4392-f5a6-5a3049f626da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 52.3MB/s 0.1s\n",
            "Ultralytics 8.3.241 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./aortic_valve_colab.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 14.1MB/s 0.1s\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1781.5Â±440.6 MB/s, size: 108.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/train/labels... 2168 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2168/2168 1.8Kit/s 1.2s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1636.4Â±996.1 MB/s, size: 114.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/val/labels... 292 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 292/292 1.5Kit/s 0.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/val/labels.cache\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      2.22G       1.86      3.391       1.46          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 2.2it/s 1:01\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 1.1it/s 9.3s\n",
            "                   all        292        292     0.0595      0.548     0.0505     0.0295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20      2.61G       1.41      1.662      1.164         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.4it/s 40.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.6it/s 2.8s\n",
            "                   all        292        292      0.808      0.818      0.866       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      2.62G      1.369      1.221      1.143          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.5it/s 39.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 2.5it/s 3.9s\n",
            "                   all        292        292      0.472      0.675      0.559      0.257\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20      2.64G      1.291      1.027      1.105          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.5it/s 38.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 2.9it/s 3.5s\n",
            "                   all        292        292      0.825      0.699      0.842      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      2.65G      1.286      0.937      1.107          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.5it/s 39.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 2.4it/s 4.2s\n",
            "                   all        292        292      0.733       0.89      0.873      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20      2.67G      1.214     0.8591      1.075          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.4it/s 39.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.4it/s 2.9s\n",
            "                   all        292        292      0.818       0.94      0.932      0.623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20      2.68G      1.174     0.8093      1.061         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.5it/s 38.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.0it/s 3.3s\n",
            "                   all        292        292      0.826      0.904      0.917      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20       2.7G      1.169      0.786      1.049         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.5it/s 39.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 2.4it/s 4.2s\n",
            "                   all        292        292      0.792      0.798      0.861      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20      2.71G       1.14     0.7481      1.045         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.5it/s 39.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.2it/s 3.1s\n",
            "                   all        292        292      0.868      0.955      0.944      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20      2.73G      1.115     0.7365      1.027         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.5it/s 39.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.4it/s 3.0s\n",
            "                   all        292        292      0.801      0.942      0.903      0.617\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20      2.74G      1.029     0.6334     0.9962          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.3it/s 41.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.7it/s 2.7s\n",
            "                   all        292        292      0.815      0.949      0.934       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20      2.76G      1.018     0.6209     0.9894          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.6it/s 37.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.3it/s 3.0s\n",
            "                   all        292        292      0.833      0.937      0.928      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20      2.77G     0.9922     0.6031     0.9833          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.6it/s 37.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.4it/s 3.0s\n",
            "                   all        292        292      0.821      0.904      0.916      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20      2.79G     0.9758      0.572     0.9733          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.6it/s 37.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.2it/s 3.1s\n",
            "                   all        292        292      0.873      0.966      0.959      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20       2.8G     0.9679     0.5631      0.967          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.7it/s 37.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 2.7it/s 3.8s\n",
            "                   all        292        292      0.843      0.914      0.942      0.676\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20      2.82G     0.9342     0.5357     0.9492          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.6it/s 37.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.5it/s 2.8s\n",
            "                   all        292        292      0.884      0.936      0.941      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20      2.83G     0.9211     0.5162     0.9486          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.6it/s 37.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.5it/s 2.9s\n",
            "                   all        292        292      0.845      0.917      0.918      0.644\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20      2.85G     0.8949     0.4967     0.9444          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.6it/s 37.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.3it/s 3.1s\n",
            "                   all        292        292      0.888      0.949      0.942      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20      2.86G     0.8755     0.4812     0.9387          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.6it/s 37.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 2.5it/s 4.1s\n",
            "                   all        292        292      0.885      0.942      0.949      0.658\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20      2.88G     0.8538     0.4667     0.9249          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 3.5it/s 38.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 3.1it/s 3.3s\n",
            "                   all        292        292      0.892      0.949      0.948      0.671\n",
            "\n",
            "20 epochs completed in 0.244 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.241 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 10/10 2.2it/s 4.5s\n",
            "                   all        292        292       0.87      0.962      0.957      0.687\n",
            "Speed: 0.2ms preprocess, 2.6ms inference, 0.0ms loss, 4.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "base_root = \"/content/datasets/test/tmp\"\n",
        "dst_root1 = \"/content/datasets/test/images1\"\n",
        "dst_root2 = \"/content/datasets/test/images2\"\n",
        "\n",
        "os.makedirs(dst_root1, exist_ok=True)\n",
        "os.makedirs(dst_root2, exist_ok=True)\n",
        "\n",
        "# è‡ªå‹•æ‰¾åˆ°ç¬¬ä¸€å€‹ã€Œç›´å±¬å­è³‡æ–™å¤¾å« patient*ã€çš„ç›®éŒ„\n",
        "patient_root = base_root\n",
        "for dirpath, dirnames, _ in os.walk(base_root):\n",
        "    if any(d.lower().startswith(\"patient\") for d in dirnames):\n",
        "        patient_root = dirpath\n",
        "        break\n",
        "\n",
        "# æ”¶é›†æ‰€æœ‰åœ–ç‰‡è·¯å¾‘ï¼ˆåªçœ‹ç›´å±¬çš„ patient è³‡æ–™å¤¾ï¼‰\n",
        "all_files = []\n",
        "for patient_folder in os.listdir(patient_root):\n",
        "    patient_path = os.path.join(patient_root, patient_folder)\n",
        "    if os.path.isdir(patient_path) and patient_folder.lower().startswith(\"patient\"):\n",
        "        for fname in os.listdir(patient_path):\n",
        "            if fname.lower().endswith(\".png\"):\n",
        "                all_files.append(os.path.join(patient_path, fname))\n",
        "\n",
        "# æŒ‰åç¨±æ’åºä¸¦å°åŠç§»å‹•\n",
        "all_files.sort()\n",
        "half = len(all_files) // 2\n",
        "\n",
        "for f in all_files[:half]:\n",
        "    shutil.move(f, os.path.join(dst_root1, os.path.basename(f)))\n",
        "\n",
        "for f in all_files[half:]:\n",
        "    shutil.move(f, os.path.join(dst_root2, os.path.basename(f)))\n",
        "\n",
        "print(f\"ä¾†æºæ ¹ç›®éŒ„ï¼š{patient_root}\")\n",
        "print(f\"å®Œæˆç§»å‹•ï¼ç¸½å…± {len(all_files)} å¼µï¼Œå‰åŠ {half} å¼µåˆ° images1ï¼Œå¾ŒåŠ {len(all_files)-half} å¼µåˆ° images2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nePC-ohmaVC6",
        "outputId": "e633d400-0c86-4605-fe3e-028f021f34ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ä¾†æºæ ¹ç›®éŒ„ï¼š/content/datasets/test/tmp/testing_image\n",
            "å®Œæˆç§»å‹•ï¼ç¸½å…± 16620 å¼µï¼Œå‰åŠ 8310 å¼µåˆ° images1ï¼Œå¾ŒåŠ 8310 å¼µåˆ° images2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt') #è«‹è‡ªè¡Œæ›´æ”¹æœ€æ–°çš„best.ptæª”è·¯å¾‘\n",
        "results = model.predict(source=\"./datasets/test/images1/\",\n",
        "              save=True,\n",
        "              imgsz=640,\n",
        "              device=0\n",
        "              )"
      ],
      "metadata": {
        "id": "yhDXBuGubnEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfWVVYt4cGQ0",
        "outputId": "3cc35221-642d-449a-ca11-2c536152fd1e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./predict_txt/\n",
        "output_file = open('./predict_txt/images1.txt', 'w')\n",
        "for i in range(len(results)):\n",
        "    # å–å¾—åœ–ç‰‡æª”åï¼ˆä¸å«å‰¯æª”åï¼‰\n",
        "    filename = results[i].path.split('/')[-1].split('.png')[0]\n",
        "\n",
        "    # å–å¾—é æ¸¬æ¡†æ•¸é‡\n",
        "    boxes = results[i].boxes\n",
        "    box_num = len(boxes.cls.tolist())\n",
        "\n",
        "    # å¦‚æœæœ‰é æ¸¬æ¡†\n",
        "    if box_num > 0:\n",
        "        for j in range(box_num):\n",
        "            # æå–è³‡è¨Š\n",
        "            label = int(boxes.cls[j].item())  # é¡åˆ¥\n",
        "            conf = boxes.conf[j].item()       # ä¿¡å¿ƒåº¦\n",
        "            x1, y1, x2, y2 = boxes.xyxy[j].tolist()  # é‚Šç•Œæ¡†åº§æ¨™\n",
        "\n",
        "            # å»ºç«‹ä¸€è¡Œè³‡æ–™\n",
        "            line = f\"{filename} {label} {conf:.4f} {int(x1)} {int(y1)} {int(x2)} {int(y2)}\\n\"\n",
        "            output_file.write(line)\n",
        "\n",
        "# é—œé–‰è¼¸å‡ºæª”æ¡ˆ\n",
        "output_file.close()"
      ],
      "metadata": {
        "id": "Dm_DI2nWcGs3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ,gc\n",
        "\n",
        "# åˆªé™¤å¤§å‹è®Šæ•¸\n",
        "del boxes,all_files,results\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dhL_t32icG6x"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('/content/runs/detect/train/weights/best.pt')\n",
        "results = model.predict(source=\"./datasets/test/images2/\",\n",
        "              save=True,\n",
        "              imgsz=640,\n",
        "              device=0\n",
        "              )"
      ],
      "metadata": {
        "id": "gNUmBSxacZ2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = open('./predict_txt/images2.txt', 'w')\n",
        "for i in range(len(results)):\n",
        "    # å–å¾—åœ–ç‰‡æª”åï¼ˆä¸å«å‰¯æª”åï¼‰\n",
        "    filename = results[i].path.split('/')[-1].split('.png')[0]\n",
        "\n",
        "    # å–å¾—é æ¸¬æ¡†æ•¸é‡\n",
        "    boxes = results[i].boxes\n",
        "    box_num = len(boxes.cls.tolist())\n",
        "\n",
        "    # å¦‚æœæœ‰é æ¸¬æ¡†\n",
        "    if box_num > 0:\n",
        "        for j in range(box_num):\n",
        "            # æå–è³‡è¨Š\n",
        "            label = int(boxes.cls[j].item())  # é¡åˆ¥\n",
        "            conf = boxes.conf[j].item()       # ä¿¡å¿ƒåº¦\n",
        "            x1, y1, x2, y2 = boxes.xyxy[j].tolist()  # é‚Šç•Œæ¡†åº§æ¨™\n",
        "\n",
        "            # å»ºç«‹ä¸€è¡Œè³‡æ–™\n",
        "            line = f\"{filename} {label} {conf:.4f} {int(x1)} {int(y1)} {int(x2)} {int(y2)}\\n\"\n",
        "            output_file.write(line)\n",
        "\n",
        "# é—œé–‰è¼¸å‡ºæª”æ¡ˆ\n",
        "output_file.close()"
      ],
      "metadata": {
        "id": "LU_TmM_dcdcd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = \"./predict_txt/images1.txt\"\n",
        "file2 = \"./predict_txt/images2.txt\"\n",
        "output = \"./predict_txt/merged.txt\"\n",
        "\n",
        "with open(output, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for f in [file1, file2]:\n",
        "        if os.path.exists(f):\n",
        "            with open(f, \"r\", encoding=\"utf-8\") as fin:\n",
        "                fout.writelines(fin.readlines())\n",
        "\n",
        "print(f\"åˆä½µå®Œæˆ -> {output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSE_ohLpcyml",
        "outputId": "f8ce3f0f-9247-45fe-d102-2244bc4a4c68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "åˆä½µå®Œæˆ -> ./predict_txt/merged.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch ,gc\n",
        "\n",
        "# åˆªé™¤å¤§å‹è®Šæ•¸\n",
        "del boxes,all_files,results\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "X81neUIUcy-7",
        "outputId": "bda69c41-92e0-4bfd-baeb-5bdc6579f019"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'all_files' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-717551557.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# åˆªé™¤å¤§å‹è®Šæ•¸\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_files' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo detect val model=/content/runs/detect/train/weights/best.pt data=aortic_valve_colab.yaml split=test save_txt save_conf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFiQ5tg1c8yr",
        "outputId": "aff047e1-75ec-4bfd-96ce-a6610d71b381"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.241 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 36.6Â±9.2 MB/s, size: 109.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/test/labels... 327 images, 1490 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1817/1817 1.3Kit/s 1.4s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/test/labels.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 114/114 5.1it/s 22.3s\n",
            "                   all       1817        327      0.896      0.893      0.941      0.597\n",
            "Speed: 1.5ms preprocess, 3.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import yaml\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ==================== 1. è¨­å®šå€ (è«‹ç¢ºèªé€™äº›è·¯å¾‘) ====================\n",
        "# æ¨¡å‹è·¯å¾‘ (è«‹ç¢ºèªä½ çš„è¨“ç·´æ¬Šé‡è·¯å¾‘æ˜¯å¦æ­£ç¢º)\n",
        "MODEL_PATH = 'runs/detect/train/weights/best.pt'\n",
        "# è³‡æ–™é›†è¨­å®šæª”\n",
        "YAML_PATH = 'aortic_valve_colab.yaml'\n",
        "# æ¸¬è©¦è³‡æ–™åœ–ç‰‡è·¯å¾‘ (YOLOé©—è­‰æ™‚éœ€è¦çš„åŸå§‹åœ–ç‰‡)\n",
        "TEST_IMAGES_DIR = 'datasets/test/images'\n",
        "# æ¸¬è©¦è³‡æ–™æ¨™ç±¤è·¯å¾‘ (Ground Truth)\n",
        "TEST_LABELS_DIR = 'datasets/test/labels'\n",
        "# è¼¸å‡ºå ±å‘Šçš„è³‡æ–™å¤¾\n",
        "OUTPUT_DIR = 'final_report_output'\n",
        "\n",
        "# ==================== 2. åŸ·è¡Œ YOLO é©—è­‰ (é—œéµä¿®æ­£) ====================\n",
        "print(\"ğŸš€ æ­£åœ¨åŸ·è¡Œ YOLO é©—è­‰ï¼Œä¸¦å¼·åˆ¶è¼¸å‡ºé æ¸¬ txt æª”...\")\n",
        "\n",
        "# æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å‰‡æç¤º\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ¬Šé‡ {MODEL_PATH}ï¼Œè«‹æª¢æŸ¥è·¯å¾‘ã€‚\")\n",
        "else:\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    # é€™è£¡çš„é‡é»æ˜¯ save_txt=True (å­˜æ¨™ç±¤) å’Œ save_conf=True (å­˜ä¿¡å¿ƒåº¦)\n",
        "    # project å’Œ name æŒ‡å®šè¼¸å‡ºä½ç½®ï¼Œæ–¹ä¾¿æˆ‘å€‘ç­‰ä¸€ä¸‹æŠ“å–\n",
        "    results = model.val(\n",
        "        data=YAML_PATH,\n",
        "        split='test',\n",
        "        save_txt=True,\n",
        "        save_conf=True,\n",
        "        conf=0.25,      # ä¿¡å¿ƒåº¦é–€æª»ï¼Œå¯è‡ªè¡Œèª¿æ•´\n",
        "        iou=0.5,        # NMS IoU é–€æª»\n",
        "        project='runs/detect',\n",
        "        name='val_final', # å›ºå®šè¼¸å‡ºåˆ° runs/detect/val_finalï¼Œæ–¹ä¾¿è®€å–\n",
        "        exist_ok=True     # å¦‚æœè³‡æ–™å¤¾å­˜åœ¨å°±è¦†è“‹ï¼Œé¿å…ç”Ÿå‡º val2, val3\n",
        "    )\n",
        "\n",
        "print(\"âœ… YOLO é©—è­‰å®Œæˆï¼\")\n",
        "\n",
        "# ==================== 3. é©—è­‰çµæœåˆ†æèˆ‡å ±å‘Šç”Ÿæˆ ====================\n",
        "print(\"ğŸ“Š é–‹å§‹é€²è¡Œ IoU æ¯”å°èˆ‡å ±å‘Šç”Ÿæˆ...\")\n",
        "\n",
        "# å®šç¾©é æ¸¬çµæœè·¯å¾‘ (å› ç‚ºä¸Šé¢æŒ‡å®šäº† name='val_final'ï¼Œæ‰€ä»¥è·¯å¾‘æ˜¯å›ºå®šçš„)\n",
        "PRED_DIR = 'runs/detect/val_final/labels'\n",
        "\n",
        "# å»ºç«‹è¼¸å‡ºç›®éŒ„\n",
        "if os.path.exists(OUTPUT_DIR):\n",
        "    shutil.rmtree(OUTPUT_DIR) # æ¸…ç©ºèˆŠçš„\n",
        "os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# è®€å–é¡åˆ¥åç¨±\n",
        "class_names = {0: 'object'} # é è¨­\n",
        "if hasattr(model, 'names'):\n",
        "    class_names = model.names\n",
        "\n",
        "# æº–å‚™çµ±è¨ˆè®Šæ•¸\n",
        "stats = {\n",
        "    \"total_images\": 0, \"total_gt\": 0, \"total_pred\": 0,\n",
        "    \"tp\": 0, \"fp\": 0, \"fn\": 0, \"dup\": 0\n",
        "}\n",
        "report_rows = []\n",
        "\n",
        "# è®€å–åœ–ç‰‡åˆ—è¡¨\n",
        "img_paths = sorted(glob.glob(os.path.join(TEST_IMAGES_DIR, '*')))\n",
        "if not img_paths:\n",
        "    print(f\"âŒ è­¦å‘Šï¼šåœ¨ {TEST_IMAGES_DIR} æ‰¾ä¸åˆ°æ¸¬è©¦åœ–ç‰‡ï¼\")\n",
        "\n",
        "def parse_yolo_txt(path, width, height):\n",
        "    \"\"\"è®€å– YOLO txt è½‰ç‚ºåƒç´ åº§æ¨™ [class, x1, y1, x2, y2, conf]\"\"\"\n",
        "    boxes = []\n",
        "    if os.path.exists(path):\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f:\n",
        "                d = list(map(float, line.strip().split()))\n",
        "                cls = int(d[0])\n",
        "                cx, cy, w, h = d[1], d[2], d[3], d[4]\n",
        "                conf = d[5] if len(d) > 5 else 1.0\n",
        "\n",
        "                x1 = int((cx - w/2) * width)\n",
        "                y1 = int((cy - h/2) * height)\n",
        "                x2 = int((cx + w/2) * width)\n",
        "                y2 = int((cy + h/2) * height)\n",
        "                boxes.append({'cls': cls, 'box': [x1, y1, x2, y2], 'conf': conf})\n",
        "    return boxes\n",
        "\n",
        "def compute_iou(boxA, boxB):\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
        "    return iou\n",
        "\n",
        "# é€å¼µåœ–ç‰‡è™•ç†\n",
        "for img_path in img_paths:\n",
        "    stats[\"total_images\"] += 1\n",
        "    filename = os.path.basename(img_path)\n",
        "    file_id = os.path.splitext(filename)[0]\n",
        "\n",
        "    # è®€å–åœ–ç‰‡\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None: continue\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    # è®€å– GT å’Œ Pred\n",
        "    gt_path = os.path.join(TEST_LABELS_DIR, file_id + '.txt')\n",
        "    pred_path = os.path.join(PRED_DIR, file_id + '.txt')\n",
        "\n",
        "    gts = parse_yolo_txt(gt_path, w, h)\n",
        "    preds = parse_yolo_txt(pred_path, w, h)\n",
        "\n",
        "    stats[\"total_gt\"] += len(gts)\n",
        "    stats[\"total_pred\"] += len(preds)\n",
        "\n",
        "    # åŒ¹é…é‚è¼¯\n",
        "    gt_matched = [False] * len(gts)\n",
        "    pred_matched = [False] * len(preds)\n",
        "\n",
        "    # 1. æ‰¾ TP (æ­£ç¢ºé æ¸¬)\n",
        "    for i, p in enumerate(preds):\n",
        "        best_iou = 0\n",
        "        best_gt_idx = -1\n",
        "        for j, g in enumerate(gts):\n",
        "            if p['cls'] == g['cls']: # é¡åˆ¥éœ€ç›¸åŒ\n",
        "                iou = compute_iou(p['box'], g['box'])\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_gt_idx = j\n",
        "\n",
        "        if best_iou >= 0.5:\n",
        "            if not gt_matched[best_gt_idx]:\n",
        "                gt_matched[best_gt_idx] = True\n",
        "                pred_matched[i] = True\n",
        "                stats[\"tp\"] += 1\n",
        "                # ç¹ªåœ–: TP (ç´…è‰²å¯¦ç·š)\n",
        "                cv2.rectangle(img, (p['box'][0], p['box'][1]), (p['box'][2], p['box'][3]), (0, 0, 255), 1)\n",
        "                cv2.putText(img, f\"{p['conf']:.2f}\", (p['box'][0], p['box'][1]-5), 0, 0.4, (0, 0, 255), 1)\n",
        "            else:\n",
        "                stats[\"dup\"] += 1\n",
        "                report_rows.append(f\"| {filename} | é‡è¤‡åµæ¸¬ | IOU: {best_iou:.2f} |\")\n",
        "        else:\n",
        "            # é€™æ˜¯ FP (å¦‚æœ IoU ä¸å¤ é«˜)\n",
        "            pass\n",
        "\n",
        "    # 2. æ‰¾ FP (èª¤å ±)\n",
        "    for i, p in enumerate(preds):\n",
        "        if not pred_matched[i]:\n",
        "            stats[\"fp\"] += 1\n",
        "            report_rows.append(f\"| {filename} | èª¤å ± (FP) | Conf: {p['conf']:.2f} |\")\n",
        "            # ç¹ªåœ–: FP (é»ƒè‰²è™›ç·šæ•ˆæœ - é€™è£¡ç”¨é»ƒè‰²å¯¦ç·šä»£æ›¿)\n",
        "            cv2.rectangle(img, (p['box'][0], p['box'][1]), (p['box'][2], p['box'][3]), (0, 255, 255), 1)\n",
        "            cv2.putText(img, \"FP\", (p['box'][0], p['box'][3]+15), 0, 0.4, (0, 255, 255), 1)\n",
        "\n",
        "    # 3. æ‰¾ FN (æ¼æ¸¬)\n",
        "    for j, g in enumerate(gts):\n",
        "        if not gt_matched[j]:\n",
        "            stats[\"fn\"] += 1\n",
        "            report_rows.append(f\"| {filename} | æ¼æ¸¬ (FN) | Class: {g['cls']} |\")\n",
        "            # ç¹ªåœ–: FN (ç¶ è‰²å¯¦ç·š) GT\n",
        "            cv2.rectangle(img, (g['box'][0], g['box'][1]), (g['box'][2], g['box'][3]), (0, 255, 0), 1)\n",
        "            cv2.putText(img, \"GT(Miss)\", (g['box'][0], g['box'][1]-5), 0, 0.4, (0, 255, 0), 1)\n",
        "\n",
        "    # å„²å­˜åœ–ç‰‡\n",
        "    cv2.imwrite(os.path.join(OUTPUT_DIR, filename), img)\n",
        "\n",
        "# ç”Ÿæˆ Markdown å ±å‘Š\n",
        "report_path = 'è©³ç´°é©—è­‰å ±å‘Š.md'\n",
        "with open(report_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(f\"# YOLO æ¨¡å‹é©—è­‰å ±å‘Š\\n\\n\")\n",
        "    f.write(f\"## 1. ç¸½é«”çµ±è¨ˆ\\n\")\n",
        "    f.write(f\"- æ¸¬è©¦åœ–ç‰‡ç¸½æ•¸: {stats['total_images']}\\n\")\n",
        "    f.write(f\"- æ¨™è¨»ç‰©ä»¶æ•¸ (GT): {stats['total_gt']}\\n\")\n",
        "    f.write(f\"- æ¨¡å‹é æ¸¬æ•¸ (Pred): {stats['total_pred']}\\n\\n\")\n",
        "    f.write(f\"### æ•ˆèƒ½æŒ‡æ¨™\\n\")\n",
        "    f.write(f\"- **æ­£ç¢ºé æ¸¬ (TP)**: {stats['tp']}\\n\")\n",
        "    f.write(f\"- **æ¼å ± (FN)** (è©²æŠ“æ²’æŠ“åˆ°): {stats['fn']}\\n\")\n",
        "    f.write(f\"- **èª¤å ± (FP)** (äº‚æŠ“): {stats['fp']}\\n\")\n",
        "    f.write(f\"- **é‡è¤‡åµæ¸¬**: {stats['dup']}\\n\\n\")\n",
        "    f.write(f\"## 2. è©³ç´°ç•°å¸¸åˆ—è¡¨\\n\")\n",
        "    f.write(\"| æª”å | éŒ¯èª¤é¡å‹ | è©³æƒ… |\\n\")\n",
        "    f.write(\"|---|---|---|\\n\")\n",
        "    for row in report_rows[:100]: # é¿å…å ±å‘Šå¤ªé•·ï¼Œåªåˆ—å‡ºå‰100ç­†ç•°å¸¸\n",
        "        f.write(row + \"\\n\")\n",
        "    if len(report_rows) > 100:\n",
        "        f.write(f\"| ... | ... | (é‚„æœ‰ {len(report_rows)-100} ç­†ç•°å¸¸æœªåˆ—å‡º) |\\n\")\n",
        "\n",
        "print(f\"\\nâœ… å…¨éƒ¨å®Œæˆï¼\")\n",
        "print(f\"1. è¦–è¦ºåŒ–åœ–ç‰‡å·²å­˜å…¥: {OUTPUT_DIR}/ (ç¶ è‰²=æ¼æ¸¬, ç´…è‰²=é æ¸¬, é»ƒè‰²=èª¤å ±)\")\n",
        "print(f\"2. è©³ç´°å ±å‘Šå·²å­˜ç‚º: {report_path}\")\n",
        "\n",
        "# æ‰“åŒ…ä¸‹è¼‰ (é¸ç”¨)\n",
        "# shutil.make_archive('é©—è­‰çµæœæ‰“åŒ…', 'zip', OUTPUT_DIR)\n",
        "# print(\"å·²å»ºç«‹ 'é©—è­‰çµæœæ‰“åŒ….zip'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP7YG0a4iBNO",
        "outputId": "5fa2eb1e-2d6c-4482-fe5d-2d05b984c2e3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ æ­£åœ¨åŸ·è¡Œ YOLO é©—è­‰ï¼Œä¸¦å¼·åˆ¶è¼¸å‡ºé æ¸¬ txt æª”...\n",
            "Ultralytics 8.3.241 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 540.2Â±885.6 MB/s, size: 107.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/test/labels.cache... 327 images, 1490 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1817/1817 2.8Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 114/114 6.9it/s 16.4s\n",
            "                   all       1817        327      0.906      0.893       0.94      0.634\n",
            "Speed: 1.7ms preprocess, 3.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val_final\u001b[0m\n",
            "âœ… YOLO é©—è­‰å®Œæˆï¼\n",
            "ğŸ“Š é–‹å§‹é€²è¡Œ IoU æ¯”å°èˆ‡å ±å‘Šç”Ÿæˆ...\n",
            "\n",
            "âœ… å…¨éƒ¨å®Œæˆï¼\n",
            "1. è¦–è¦ºåŒ–åœ–ç‰‡å·²å­˜å…¥: final_report_output/ (ç¶ è‰²=æ¼æ¸¬, ç´…è‰²=é æ¸¬, é»ƒè‰²=èª¤å ±)\n",
            "2. è©³ç´°å ±å‘Šå·²å­˜ç‚º: è©³ç´°é©—è­‰å ±å‘Š.md\n"
          ]
        }
      ]
    }
  ]
}